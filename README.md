# a1_fall_rec  

A simple implementation of fall recovery for unitree a1 based on DRL. Domain Randomization Used.   

If you have more interest in robot fall recovery, you may read:

+ Which seems the most robust way, but a bit troublesome:  
Zhang, C., Yu, W., & Li, Z. (2022, May). Accessibility-based clustering for efficient learning of locomotion skills. In 2022 International Conference on Robotics and Automation (ICRA) (pp. 1600-1606). IEEE.  
+ Which is close to this implementation, but shows that jueying and a1 are greatly different:  
Yang, C., Yuan, K., Zhu, Q., Yu, W., & Li, Z. (2020). Multi-expert learning of adaptive legged locomotion. Science Robotics, 5(49), eabb2174.   
+ Which may be more suitable for A1:   
Smith, L., Kew, J. C., Peng, X. B., Ha, S., Tan, J., & Levine, S. (2022, May). Legged robots that keep on learning: Fine-tuning locomotion policies in the real world. In 2022 International Conference on Robotics and Automation (ICRA) (pp. 1593-1599). IEEE.  
+ Which consists multiple stages:   
Lee, J., Hwangbo, J., & Hutter, M. (2019). Robust recovery controller for a quadrupedal robot using deep reinforcement learning. arXiv preprint arXiv:1901.07517.  


`main.py` to train

`test.py` to evaluate
